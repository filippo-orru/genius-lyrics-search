{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.8.1)\n",
      "Collecting swifter\n",
      "  Downloading swifter-1.4.0.tar.gz (1.2 MB)\n",
      "Requirement already satisfied: click in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: tqdm in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: joblib in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: pandas>=1.0.0 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from swifter) (2.1.4)\n",
      "Requirement already satisfied: psutil>=5.6.6 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from swifter) (5.9.6)\n",
      "Collecting dask[dataframe]>=2.10.0\n",
      "  Downloading dask-2023.12.1-py3-none-any.whl (1.2 MB)\n",
      "Requirement already satisfied: ipywidgets>=7.0.0 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from swifter) (8.1.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.13.0 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (6.8.0)\n",
      "Collecting partd>=1.2.0\n",
      "  Downloading partd-1.4.1-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (23.2)\n",
      "Collecting cloudpickle>=1.5.0\n",
      "  Downloading cloudpickle-3.0.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (6.0.1)\n",
      "Collecting toolz>=0.10.0\n",
      "  Downloading toolz-0.12.0-py3-none-any.whl (55 kB)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (2023.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from importlib-metadata>=4.13.0->dask[dataframe]>=2.10.0->swifter) (3.17.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.9 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipywidgets>=7.0.0->swifter) (4.0.9)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipywidgets>=7.0.0->swifter) (0.2.0)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipywidgets>=7.0.0->swifter) (8.17.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipywidgets>=7.0.0->swifter) (5.13.0)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipywidgets>=7.0.0->swifter) (3.0.9)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (0.19.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (4.8.0)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (1.1.3)\n",
      "Requirement already satisfied: decorator in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (5.1.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (0.1.6)\n",
      "Requirement already satisfied: stack-data in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (0.6.3)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (2.16.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (3.0.39)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (0.8.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=1.0.0->swifter) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=1.0.0->swifter) (2023.3)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=1.0.0->swifter) (1.26.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=1.0.0->swifter) (2.8.2)\n",
      "Collecting locket\n",
      "  Downloading locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (0.2.9)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->swifter) (1.16.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (0.2.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\paula\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7.0.0->swifter) (2.0.1)\n",
      "Building wheels for collected packages: swifter\n",
      "  Building wheel for swifter (setup.py): started\n",
      "  Building wheel for swifter (setup.py): finished with status 'done'\n",
      "  Created wheel for swifter: filename=swifter-1.4.0-py3-none-any.whl size=16513 sha256=201c9933a2e9b6b98fb446761713acc7cc463baa4056b8ab4940750469b5acb8\n",
      "  Stored in directory: c:\\users\\paula\\appdata\\local\\pip\\cache\\wheels\\7b\\4a\\7e\\bcc48cf10e10fcf5b4dae464a66b523756db6b950e02129680\n",
      "Successfully built swifter\n",
      "Installing collected packages: toolz, locket, partd, cloudpickle, dask, swifter\n",
      "Successfully installed cloudpickle-3.0.0 dask-2023.12.1 locket-1.0.0 partd-1.4.1 swifter-1.4.0 toolz-0.12.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\paula\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk swifter swifter[notebook]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "import string\n",
    "import swifter\n",
    "import torch\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv file\n",
    "df = pd.read_csv('subset-song-lyrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of songs: 12295\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>tag</th>\n",
       "      <th>artist</th>\n",
       "      <th>year</th>\n",
       "      <th>views</th>\n",
       "      <th>features</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>id</th>\n",
       "      <th>language_cld3</th>\n",
       "      <th>language_ft</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Killa Cam</td>\n",
       "      <td>rap</td>\n",
       "      <td>Cam'ron</td>\n",
       "      <td>2004</td>\n",
       "      <td>173166</td>\n",
       "      <td>{\"Cam\\\\'ron\",\"Opera Steve\"}</td>\n",
       "      <td>[Chorus: Opera Steve &amp; Cam'ron]\\nKilla Cam, Ki...</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can I Live</td>\n",
       "      <td>rap</td>\n",
       "      <td>JAY-Z</td>\n",
       "      <td>1996</td>\n",
       "      <td>468624</td>\n",
       "      <td>{}</td>\n",
       "      <td>[Produced by Irv Gotti]\\n\\n[Intro]\\nYeah, hah,...</td>\n",
       "      <td>3</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Forgive Me Father</td>\n",
       "      <td>rap</td>\n",
       "      <td>Fabolous</td>\n",
       "      <td>2003</td>\n",
       "      <td>4743</td>\n",
       "      <td>{}</td>\n",
       "      <td>Maybe cause I'm eatin\\nAnd these bastards fien...</td>\n",
       "      <td>4</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Down and Out</td>\n",
       "      <td>rap</td>\n",
       "      <td>Cam'ron</td>\n",
       "      <td>2004</td>\n",
       "      <td>144404</td>\n",
       "      <td>{\"Cam\\\\'ron\",\"Kanye West\",\"Syleena Johnson\"}</td>\n",
       "      <td>[Produced by Kanye West and Brian Miller]\\n\\n[...</td>\n",
       "      <td>5</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fly In</td>\n",
       "      <td>rap</td>\n",
       "      <td>Lil Wayne</td>\n",
       "      <td>2005</td>\n",
       "      <td>78271</td>\n",
       "      <td>{}</td>\n",
       "      <td>[Intro]\\nSo they ask me\\n\"Young boy\\nWhat you ...</td>\n",
       "      <td>6</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               title  tag     artist  year   views  \\\n",
       "0          Killa Cam  rap    Cam'ron  2004  173166   \n",
       "1         Can I Live  rap      JAY-Z  1996  468624   \n",
       "2  Forgive Me Father  rap   Fabolous  2003    4743   \n",
       "3       Down and Out  rap    Cam'ron  2004  144404   \n",
       "4             Fly In  rap  Lil Wayne  2005   78271   \n",
       "\n",
       "                                       features  \\\n",
       "0                   {\"Cam\\\\'ron\",\"Opera Steve\"}   \n",
       "1                                            {}   \n",
       "2                                            {}   \n",
       "3  {\"Cam\\\\'ron\",\"Kanye West\",\"Syleena Johnson\"}   \n",
       "4                                            {}   \n",
       "\n",
       "                                              lyrics  id language_cld3  \\\n",
       "0  [Chorus: Opera Steve & Cam'ron]\\nKilla Cam, Ki...   1            en   \n",
       "1  [Produced by Irv Gotti]\\n\\n[Intro]\\nYeah, hah,...   3            en   \n",
       "2  Maybe cause I'm eatin\\nAnd these bastards fien...   4            en   \n",
       "3  [Produced by Kanye West and Brian Miller]\\n\\n[...   5            en   \n",
       "4  [Intro]\\nSo they ask me\\n\"Young boy\\nWhat you ...   6            en   \n",
       "\n",
       "  language_ft language  \n",
       "0          en       en  \n",
       "1          en       en  \n",
       "2          en       en  \n",
       "3          en       en  \n",
       "4          en       en  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"number of songs: {len(df)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\paula\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\paula\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12064, 12295)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(df[df[\"language\"] == \"en\"]), len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e2776fd66b047ecbf4515b45e23cb5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/12064 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "stopwords_en = set(stopwords.words('english'))\n",
    "\n",
    "# Create a copy of the dataframe\n",
    "df_proc = df.copy()\n",
    "\n",
    "# Select only english songs\n",
    "df_proc = df_proc[df_proc[\"language\"] == \"en\"]\n",
    "\n",
    "# Select columns we care about\n",
    "df_proc = df_proc[[\"title\",\"lyrics\"]]\n",
    "# Rename column\n",
    "df_proc.rename(columns={\"lyrics\": \"tokens\"}, inplace=True)\n",
    "\n",
    "# Convert to lowercase\n",
    "df_proc[\"tokens\"] = df_proc[\"tokens\"].str.lower()\n",
    "# Remove text between square brackets and any non alphanumeric / whitespace characters\n",
    "df_proc[\"tokens\"] = df_proc[\"tokens\"].str.replace(re.compile(r\"\\[.{0,100}\\]|[^\\w\\s]\"), \"\", regex=True)\n",
    "# Split text into words\n",
    "df_proc[\"tokens\"] = df_proc[\"tokens\"].str.rsplit()\n",
    "# Remove stopwords and stem tokens\n",
    "def remove_stopwords_and_stem(tokens):\n",
    "    return [ps.stem(token) for token in tokens if token not in stopwords_en]\n",
    "df_proc[\"tokens\"] = df_proc[\"tokens\"].swifter.apply(remove_stopwords_and_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('haha, uhhuh, homo, young, mula, babi, say, he, sweet, make, wanna, lick, wrapper, remix, babi, lollipop, lollipop, breasts, like, dolli',\n",
       " '[Intro: Lil Wayne]\\nHaha\\nUh-huh\\nNo homo (Young Mula, baby!)\\nI say, he\\'s so sweet, make her wanna lick the wrapper\\nRemix, baby!\\n\\n[Verse 1: Kanye West]\\nLollipop, lollipop, breastses just like Dolly Parton\\nShe ride my spaceship \\'til she hit the top\\nThat hit the spot\\n\\'Til she ask, \"How many li-i-li-i-licks do it take\" \\'til she get to shop?\\nDon\\'t worry why my wrists got so freeze\\nTell a girl, \"Like Doritos, that\\'s not \\'cho cheese\"\\nTell her friends, \"Like Fritos, I\\'m tryin\\' to lay\"\\nI can\\'t only have one, and I ain\\'t trying to wait\\nThis a song with Wayne, so you know it\\'s gon\\' melt\\nBut you ain\\'t finna murder me like everybody else\\nI\\'ma rap like I got some type respect for myself\\nI don\\'t do it for my health, man, I do it for the belt\\nMan, I do it to the death, \\'til the roof get melt\\nHundred degrees, drop the roof, so the coupe don\\'t melt\\nMan, the flow so cold, chicken soup won\\'t help\\nWe need four more hoes, we need oh, oh, oh, oh!\\nYou know what it is when we out of town\\nWe balling too serious, and you out of bounds\\nSo come here, baby girl\\nYou\\'re now fucking with the best in the world\\n[Break: Kanye West & Static Major]\\nLollipop\\nThe best in the world\\nSh-Sh-She lick me like a lollipop\\nWorld, world\\nShe‚Äî She lick me like a lollipop\\n\\n[Chorus: Static Major, Lil Wayne, & Both]\\nShawty want a thug, thug, thug\\nBottles in the club, club, club (Bottles in the club)\\nShawty wanna hump (Shawty wanna)\\nYou know I like to touch (Shawty wanna)\\nYour lovely lady lumps, lumps, lumps (Shawty wanna)\\nShawty want a thug (I like that)\\nBottles in the club (Hey, I like that)\\nShawty wanna hump (I like that, haha!)\\nYou know I like to touch your lovely lady lumps, lumps, lumps\\n\\n[Verse 2: Lil Wayne]\\nShawty say she wanna lick the wrapper\\nAnd she gonna lick the rapper\\nAnd I just wanna act like a porno-flicking actor\\nI Anita-bake her; now, she caught up in that \"Rapture\"\\nI got so much chips, I swear, they call me \"Hewlett Packard\"\\nI got so much chips, you can have a bag if you\\'re a snacker\\nGreedy mother-fudge cake; now, tell me how that fudge tastes\\nI do it for Bloods\\' sake‚Äîsoo-woo!\\nThink it\\'s voodoo how that roof do di-di-dissipate\\nYour girl want to participate\\nShe so, so sophisticate, \\'cause her brain is off the chain\\nAnd then, my diamonds are in the choir because they sing from off my chain\\nAnd my Nina just joined the gang because all she do is bang\\nLike Ricky Martin; Wayne and Kanye: pick your poison\\nIf that woman wanna cut, then tell her I am Mr. Ointment\\nTell her to make an appointment with Mr. I-Can\\'t-Make-An-Appointment\\nTake my lollipop and enjoy it‚Äîremix!\\n[Chorus: Static Major, Lil Wayne, & Both]\\nShawty want a thug, thug, thug (Shawty want a thug, yeah!)\\nBottles in the club, club, club (Bottles in the club, yeah!)\\nShawty wanna hump (Yeah! Shawty wanna)\\nYou know I like to touch (Yeah! Shawty wanna)\\nYour lovely lady lumps, lumps, lumps (Shawty wanna)\\nShawty want a thug (I like that)\\nBottles in the club (Hey, I like that)\\nShawty wanna hump (I like that, haha!)\\nYou know I like to touch your lovely lady lumps, lumps, lumps\\n\\n[Verse 3: Lil Wayne]\\nWhy would she? She probably be the odd cookie\\nIn the plastic bag \\'bout to get crushed by a building\\nI\\'ve flushed out the feeling of me being the shit\\n\\'Cause I was leaving skid marks on everywhere I sit\\nI am everywhere, I\\'m it, like Hide-and-Go\\nAnd I can go anywhere: eeny, mini, miney, mo\\nI\\'m in your neighborhood, area, CD-thing, tapedeck\\n\\u200biPod, your girlfriend, and she say I got great sex\\nSafe sex is great sex, better wear a latex\\n\\'Cause you don\\'t want that late text, that \"I think I\\'m late\" text\\nHaha! So wrap it up!\\nBu-Bu-But he\\'s so sweet, sh-she wanna lick the wrapper\\n\\n[Chorus: Static Major & Lil Wayne]\\nShawty want a thug\\nBottles in the club, club, club\\nShawty wanna hump\\nYou know I like to touch\\nYour lovely lady lumps, lumps, lumps (Re-Re-Re-Remix, baby!)\\n[Outro: Static Major]\\nLick me like a lollipop (Lollipop)\\nShe‚Äî She lick me like a lollipop (L-Lollipop)\\nSh-Sh-Sh-She lick me like a lollipop (Lollipop)\\nShe‚Äî She lick me like a lollipop (Lollipop)')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\", \".join(df_proc.iloc[5][\"tokens\"][:20]), df.iloc[5][\"lyrics\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Killa Cam</td>\n",
       "      <td>[killa, cam, killa, cam, cam, killa, cam, kill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can I Live</td>\n",
       "      <td>[yeah, hah, yeah, rocafella, invit, somethin, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Forgive Me Father</td>\n",
       "      <td>[mayb, caus, im, eatin, bastard, fiend, grub, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Down and Out</td>\n",
       "      <td>[ugh, killa, babi, kany, 1970, heron, flow, hu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fly In</td>\n",
       "      <td>[ask, young, boy, gon, second, time, around, g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               title                                             tokens\n",
       "0          Killa Cam  [killa, cam, killa, cam, cam, killa, cam, kill...\n",
       "1         Can I Live  [yeah, hah, yeah, rocafella, invit, somethin, ...\n",
       "2  Forgive Me Father  [mayb, caus, im, eatin, bastard, fiend, grub, ...\n",
       "3       Down and Out  [ugh, killa, babi, kany, 1970, heron, flow, hu...\n",
       "4             Fly In  [ask, young, boy, gon, second, time, around, g..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Killa Cam</td>\n",
       "      <td>[killa, cam, killa, cam, cam, killa, cam, kill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can I Live</td>\n",
       "      <td>[yeah, hah, yeah, rocafella, invit, somethin, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Forgive Me Father</td>\n",
       "      <td>[mayb, caus, im, eatin, bastard, fiend, grub, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Down and Out</td>\n",
       "      <td>[ugh, killa, babi, kany, 1970, heron, flow, hu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fly In</td>\n",
       "      <td>[ask, young, boy, gon, second, time, around, g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               title                                             tokens\n",
       "0          Killa Cam  [killa, cam, killa, cam, cam, killa, cam, kill...\n",
       "1         Can I Live  [yeah, hah, yeah, rocafella, invit, somethin, ...\n",
       "2  Forgive Me Father  [mayb, caus, im, eatin, bastard, fiend, grub, ...\n",
       "3       Down and Out  [ugh, killa, babi, kany, 1970, heron, flow, hu...\n",
       "4             Fly In  [ask, young, boy, gon, second, time, around, g..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the testing-song-lyrics.csv file as a pickle file\n",
    "torch.save(df_proc, 'subset_documents.pkl')\n",
    "\n",
    "# Test if the pickle file is saved correctly\n",
    "df_reloaded = torch.load('subset_documents.pkl')\n",
    "df_reloaded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Query (still a lot to do)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to Select Verses\n",
    "def getFirstVerses(lyricsString, amount):\n",
    "    verseList = re.split('\\r\\n', lyricsString)\n",
    "    FinalList = [i for i in verseList if (len(i) > 1 and i[0] != '[')]\n",
    "    return \" \".join(FinalList[:amount])\n",
    "\n",
    "def getFirstVersesOfChorus(lyricsString, amount):\n",
    "    List = re.split('\\r\\n', lyricsString)\n",
    "    verseList = [i for i in List if len(i) > 1]\n",
    "    for i in range(len(verseList)):\n",
    "        if \"[Chorus\" in verseList[i] or \"[Hook\" in verseList[i]:\n",
    "            return \" \".join(verseList[i+1:i+amount+1])\n",
    "    return getFirstVerses(lyricsString, amount)\n",
    "\n",
    "def getRandomVerses(lyricsString, amount):\n",
    "    verseList = re.split('\\r\\n', lyricsString)\n",
    "    FinalList = [i for i in verseList if (len(i) > 1 and i[0] != '[')]\n",
    "    rd = random.randint(0,len(FinalList)-amount)\n",
    "    return \" \".join(FinalList[rd:rd+amount])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to Degrade message\n",
    "\n",
    "#Function to create typo by neighbouring letter\n",
    "NeighbouringKeys = {}\n",
    "NeighbouringKeys['q'] = \"qwas\"\n",
    "NeighbouringKeys['w'] = \"qwase\"\n",
    "NeighbouringKeys['e'] = \"wsedr\"\n",
    "NeighbouringKeys['r'] = \"edrft\"\n",
    "NeighbouringKeys['t'] = \"rftgy\"\n",
    "NeighbouringKeys['y'] = \"tgyhu\"\n",
    "NeighbouringKeys['u'] = \"yhuji\"\n",
    "NeighbouringKeys['i'] = \"ujiko\"\n",
    "NeighbouringKeys['o'] = \"ikolp\"\n",
    "NeighbouringKeys['p'] = \"olp\"\n",
    "\n",
    "NeighbouringKeys['a'] = \"qwasz\"\n",
    "NeighbouringKeys['s'] = \"wazsxed\"\n",
    "NeighbouringKeys['d'] = \"sxedcrf\"\n",
    "NeighbouringKeys['f'] = \"dcrfvtg\"\n",
    "NeighbouringKeys['g'] = \"fvtgbyh\"\n",
    "NeighbouringKeys['h'] = \"gbyhnuj\"\n",
    "NeighbouringKeys['j'] = \"hnujmik\"\n",
    "NeighbouringKeys['k'] = \"jmikol\"\n",
    "NeighbouringKeys['l'] = \"kolp\"\n",
    "\n",
    "NeighbouringKeys['z'] = \"azsx\"\n",
    "NeighbouringKeys['x'] = \"zsxdc\"\n",
    "NeighbouringKeys['c'] = \"xdcfv\"\n",
    "NeighbouringKeys['v'] = \"cfvgb\"\n",
    "NeighbouringKeys['b'] = \"vgbhn\"\n",
    "NeighbouringKeys['n'] = \"bhnjm\"\n",
    "NeighbouringKeys['m'] = \"njmk\"\n",
    "\n",
    "englishLetters = NeighbouringKeys.keys()\n",
    "\n",
    "def typos(text,prob=0.01):\n",
    "\n",
    "    resultingText = \"\"\n",
    "\n",
    "    for letter in text:\n",
    "        if not letter in englishLetters:\n",
    "            newLetter = letter\n",
    "        else:\n",
    "            if random.random() < prob:\n",
    "                newLetter = random.choice(NeighbouringKeys[letter])\n",
    "            else: \n",
    "                newLetter = letter\n",
    "        resultingText += newLetter\n",
    "    \n",
    "    return resultingText\n",
    "\n",
    "\n",
    "#Function to (maybe) invert 2 adjacent letters (do force=True to force it to happen)\n",
    "def invertAdjacentLetters(text, force=False):\n",
    "    rd = random.randint(0,len(text)-2)\n",
    "    if not force:\n",
    "        if text[rd] in englishLetters and text[rd+1] in englishLetters:\n",
    "            return text[:rd]+text[rd+1]+text[rd]+text[rd+2:]\n",
    "        else:\n",
    "            return text\n",
    "    else :\n",
    "        while not(text[rd] in englishLetters and text[rd+1] in englishLetters):\n",
    "            rd = random.randint(0,len(text)-2)\n",
    "        return text[:rd]+text[rd+1]+text[rd]+text[rd+2:]\n",
    "\n",
    "#Function to (maybe) remove a letter (do force=True to force it to happen)\n",
    "def removeLetter(text, force=False):\n",
    "    rd = random.randint(0,len(text)-1)\n",
    "    if not force:\n",
    "        if text[rd] in englishLetters:\n",
    "            return text[:rd]+text[rd+1:]\n",
    "        else:\n",
    "            return text\n",
    "    else :\n",
    "        while not(text[rd] in englishLetters):\n",
    "            rd = random.randint(0,len(text)-1)\n",
    "        return text[:rd]+text[rd+1:]\n",
    "    \n",
    "#Function to (maybe) double a letter (do force=True to force it to happen)\n",
    "def doubleLetter(text, force=False):\n",
    "    rd = random.randint(0,len(text)-1)\n",
    "    if not force:\n",
    "        if text[rd] in englishLetters:\n",
    "            return text[:rd+1]+text[rd]+text[rd+1:]\n",
    "        else:\n",
    "            return text\n",
    "    else :\n",
    "        while not(text[rd] in englishLetters):\n",
    "            rd = random.randint(0,len(text)-1)\n",
    "        return text[:rd+1]+text[rd]+text[rd+1:]\n",
    "\n",
    "#Function to add a common misspell\n",
    "CommonMisspelling = {\"absence\" : [\"absense\", \"absentse\", \"abcense\", \"absance\"], \"acceptable\" : [\"acceptible\"], \"their\" : [\"there\", \"they're\"], \"there\" : [\"their\", \"they're\"], \"they're\" : [\"their\", \"there\"], \"your\" : [\"you're\"], \"you're\" : [\"your\"]}\n",
    "\n",
    "def addCommonMisspell(text):\n",
    "    for word in CommonMisspelling.keys():\n",
    "        if word in text:\n",
    "            return text.replace(word, random.choice(CommonMisspelling[word]))\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the dataframe\n",
    "df_query = df.copy()\n",
    "\n",
    "# Select only english songs\n",
    "df_query = df_query[df_query[\"language\"] == \"en\"]\n",
    "\n",
    "# Select columns we care about\n",
    "df_query = df_query[[\"title\",\"lyrics\",\"views\"]]\n",
    "\n",
    "# Create a weight column\n",
    "maxViews = max(df_query[\"views\"])\n",
    "\n",
    "df_query[\"weight\"] = (df_query[\"views\"]/maxViews) ** 0.5 * 0.5 + 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNQueries(df,n):\n",
    "    df_sampl = df.sample(n=n, weights='weight').reset_index(drop=True)\n",
    "    Queries = []\n",
    "    for i in range(n):\n",
    "        text = df_sampl['lyrics'][i]\n",
    "        rd = random.random()\n",
    "        if rd<0.6:\n",
    "            query = getFirstVersesOfChorus(text,random.randint(1,2))\n",
    "        elif rd<0.9:\n",
    "            query = getFirstVerses(text,random.randint(1,2))\n",
    "        else:\n",
    "            query = getRandomVerses(text,random.randint(1,2))\n",
    "        if random.randint(0,1) == 0:\n",
    "            query = addCommonMisspell(query)\n",
    "        query = typos(query)\n",
    "        for j in range(random.randint(0,3)):\n",
    "            query = invertAdjacentLetters(query)\n",
    "        for j in range(random.randint(0,2)):\n",
    "            query = removeLetter(query)\n",
    "        for j in range(random.randint(0,2)):\n",
    "            query = doubleLetter(query)\n",
    "        Queries.append([query,df_sampl['title'][i]])\n",
    "    return Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty range for randrange() (0, -1, -1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mgetNQueries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_query\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[17], line 17\u001b[0m, in \u001b[0;36mgetNQueries\u001b[1;34m(df, n)\u001b[0m\n\u001b[0;32m     15\u001b[0m query \u001b[38;5;241m=\u001b[39m typos(query)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m3\u001b[39m)):\n\u001b[1;32m---> 17\u001b[0m     query \u001b[38;5;241m=\u001b[39m \u001b[43minvertAdjacentLetters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m)):\n\u001b[0;32m     19\u001b[0m     query \u001b[38;5;241m=\u001b[39m removeLetter(query)\n",
      "Cell \u001b[1;32mIn[15], line 55\u001b[0m, in \u001b[0;36minvertAdjacentLetters\u001b[1;34m(text, force)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvertAdjacentLetters\u001b[39m(text, force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m---> 55\u001b[0m     rd \u001b[38;5;241m=\u001b[39m \u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m force:\n\u001b[0;32m     57\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m text[rd] \u001b[38;5;129;01min\u001b[39;00m englishLetters \u001b[38;5;129;01mand\u001b[39;00m text[rd\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m englishLetters:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\random.py:338\u001b[0m, in \u001b[0;36mRandom.randint\u001b[1;34m(self, a, b)\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrandint\u001b[39m(\u001b[38;5;28mself\u001b[39m, a, b):\n\u001b[0;32m    335\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return random integer in range [a, b], including both end points.\u001b[39;00m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 338\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandrange\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\random.py:316\u001b[0m, in \u001b[0;36mRandom.randrange\u001b[1;34m(self, start, stop, step)\u001b[0m\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m istart \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_randbelow(width)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 316\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mempty range for randrange() (\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (istart, istop, width))\n\u001b[0;32m    318\u001b[0m \u001b[38;5;66;03m# Non-unit step argument supplied.\u001b[39;00m\n\u001b[0;32m    319\u001b[0m istep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(step)\n",
      "\u001b[1;31mValueError\u001b[0m: empty range for randrange() (0, -1, -1)"
     ]
    }
   ],
   "source": [
    "getNQueries(df_query,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to be able to work on the data easier, we are going to make a string made out of our tokens, to then do the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proc['text'] = df_proc['tokens'].apply(lambda tokens: ' '.join(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df_proc['text'])\n",
    "\n",
    "feature = tfidf_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Word    TF-IDF\n",
      "10769        cam  0.800548\n",
      "34638      killa  0.588214\n",
      "56995       sing  0.042899\n",
      "13152       clap  0.041008\n",
      "65962        uhh  0.018107\n",
      "...          ...       ...\n",
      "24039   foodmart  0.000000\n",
      "24040  foodstamp  0.000000\n",
      "24041      fooey  0.000000\n",
      "24042       foof  0.000000\n",
      "72003        ùë§ùëéùë†  0.000000\n",
      "\n",
      "[72004 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "doc_vector = tfidf_matrix[0].toarray()\n",
    "#df with words and their tf-idf values\n",
    "df_tfidf = pd.DataFrame(list(zip(feature, doc_vector.flatten())), columns=['Word', 'TF-IDF'])\n",
    "\n",
    "df_tfidf = df_tfidf.sort_values(by='TF-IDF', ascending=False)\n",
    "print(df_tfidf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
